{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This collection of scenarios demonstrates how to solve various data quality problems by exploiting patterns found (or validated) by Desbordante.\n",
        "\n",
        "In this scenario, we showcase a simple application that performs typo detection in a table.\n",
        "\n",
        "The idea of this scenario is described in the paper \"Solving Data Quality Problems with Desbordante: a Demo\" by G. Chernishev et al., available at https://arxiv.org/abs/2307.14935. There is also an interactive demo at https://desbordante.streamlit.app/."
      ],
      "metadata": {
        "id": "8iH3-Au_F1OY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Typo mining example using Desbordante algorithms."
      ],
      "metadata": {
        "id": "w0jF-5JlzE5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install desbordante==2.3.2\n",
        "!wget https://raw.githubusercontent.com/Desbordante/desbordante-core/refs/heads/main/examples/datasets/Workshop.csv\n",
        "!pip install colorama jellyfish\n",
        "\n",
        "from functools import reduce\n",
        "from itertools import groupby, islice\n",
        "import operator\n",
        "\n",
        "from colorama import Style, Fore\n",
        "from jellyfish import levenshtein_distance\n",
        "import desbordante\n",
        "import pandas\n",
        "\n",
        "def setup_pandas_print():\n",
        "    pandas.set_option('display.max_columns', None)\n",
        "    pandas.set_option('display.width', None)\n",
        "    pandas.set_option('display.max_colwidth', None)\n",
        "    pandas.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "setup_pandas_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ogzUWhlaWt",
        "outputId": "0b15b82e-1187-45dc-955f-9061849dbb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting desbordante==2.3.2\n",
            "  Downloading desbordante-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Downloading desbordante-2.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: desbordante\n",
            "Successfully installed desbordante-2.3.2\n",
            "--2025-03-20 17:45:38--  https://raw.githubusercontent.com/Desbordante/desbordante-core/refs/heads/main/examples/datasets/Workshop.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 95017 (93K) [text/plain]\n",
            "Saving to: ‘Workshop.csv’\n",
            "\n",
            "Workshop.csv        100%[===================>]  92.79K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2025-03-20 17:45:39 (10.1 MB/s) - ‘Workshop.csv’ saved [95017/95017]\n",
            "\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jellyfish in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up various algorithm parameters."
      ],
      "metadata": {
        "id": "zRAc6mNW5T6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Value cluster filtering parameters.\n",
        "RADIUS = 3\n",
        "RATIO = 0.1\n",
        "\n",
        "# Algorithm that finds exact FDs and its config.\n",
        "EXACT_ALGORITHM_TYPE = desbordante.fd.algorithms.Default\n",
        "EXACT_ALGO_CONFIG = {}\n",
        "\n",
        "# Algorithm that finds approximate FDs and its config.\n",
        "APPROXIMATE_ALGORITHM_TYPE = desbordante.afd.algorithms.Default\n",
        "ERROR = 0.005 # Highest error for almost holding FDs.\n",
        "APPROXIMATE_ALGO_CONFIG = {'error': ERROR}\n",
        "\n",
        "# Parameters for pandas.read_csv(...).\n",
        "DATASET_PATH = 'Workshop.csv'\n",
        "HEADER = 0\n",
        "SEPARATOR = ','\n",
        "\n",
        "# Index of the almost holding FD. Chosen in advance purely for\n",
        "# demonstration purposes. In a real usage scenario this should be a\n",
        "# choice for the user.\n",
        "FD_INDEX = 2\n",
        "\n",
        "\n",
        "assert APPROXIMATE_ALGO_CONFIG['error'] > 0.0, 'Typo mining relies on non-zero error'\n",
        "assert EXACT_ALGO_CONFIG.get('error', 0.0) == 0.0, 'Error must be 0 for precise algorithm'\n",
        "\n",
        "# Variables to simplify the configuration string construction below.\n",
        "EXACT_ALGORITHM = EXACT_ALGORITHM_TYPE.__name__\n",
        "APPROXIMATE_ALGORITHM = APPROXIMATE_ALGORITHM_TYPE.__name__\n",
        "\n",
        "# A message containing all variables used by this usage scenario, to be\n",
        "# displayed to the user.\n",
        "CONFIG_STRING = f\"\"\"Starting typo discovery scenario with parameters:\n",
        "{RADIUS=}\n",
        "{RATIO=}\n",
        "{ERROR=}\n",
        "{DATASET_PATH=}\n",
        "{EXACT_ALGORITHM=}\n",
        "{APPROXIMATE_ALGORITHM=}\n",
        "{HEADER=}\n",
        "{SEPARATOR=}\"\"\""
      ],
      "metadata": {
        "id": "Nty20bIy0i2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining necessary functions."
      ],
      "metadata": {
        "id": "zDJ7mdTx5uoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_squashed_sorted_clusters(dataset: pandas.DataFrame, lhs_indices, rhs_index):\n",
        "    def get_lhs(row_count_pair):\n",
        "        row, _ = row_count_pair\n",
        "        return row[:-1]\n",
        "\n",
        "    def get_rhs(row):\n",
        "        return row[-1]\n",
        "\n",
        "    def count_key(rhs_count_pair):\n",
        "        rhs, count = rhs_count_pair\n",
        "        # Sort descending on count, ascending on rhs value\n",
        "        return -count, rhs\n",
        "\n",
        "    fd_columns = [dataset.columns[col_num] for col_num in lhs_indices]\n",
        "    fd_columns.append(dataset.columns[rhs_index])\n",
        "    value_counts = dataset.value_counts(fd_columns, dropna=False)\n",
        "    # Rows with the same LHS now end up next to each other and can be\n",
        "    # grouped together with groupby. But inside each group rows may not\n",
        "    # be sorted by the number of their occurrences.\n",
        "    value_counts.sort_index(inplace=True)\n",
        "    lhs_groups = ((lhs, row_count_pairs) for lhs, row_count_iter in\n",
        "                  groupby(value_counts.items(), key=get_lhs) if\n",
        "                  # Exclude instances where FD is not violated.\n",
        "                  len(row_count_pairs := tuple(row_count_iter)) > 1)\n",
        "    # The final step is transforming lhs groups in the form of\n",
        "    # (lhs, (((*lhs, rhs_value), count), ...)) to the form\n",
        "    # (lhs, ((rhs_value, count), ...)) and sorting them by the number\n",
        "    # of occurrences in the table.\n",
        "    return [(lhs, sorted(((get_rhs(row), count) for row, count in row_count_pairs), key=count_key))\n",
        "            for lhs, row_count_pairs in lhs_groups]\n",
        "\n",
        "def number_metric(a, b):\n",
        "    return abs(a - b)\n",
        "\n",
        "\n",
        "def string_metric(a, b):\n",
        "    return levenshtein_distance(str(a), str(b))\n",
        "\n",
        "\n",
        "def filter_radius(squashed_sorted_clusters, metric) -> list:\n",
        "    def is_value_close(value_count_pair):\n",
        "        value, _ = value_count_pair\n",
        "        return metric(most_common_value, value) < RADIUS\n",
        "\n",
        "    filtered = []\n",
        "    for lhs, value_data in squashed_sorted_clusters:\n",
        "        most_common_value, _ = value_data[0]\n",
        "        close_value_pairs = list(filter(is_value_close, islice(value_data, 1, None)))\n",
        "        if close_value_pairs:\n",
        "            filtered.append((lhs, [value_data[0]] + close_value_pairs))\n",
        "    return filtered\n",
        "\n",
        "def filter_ratio(squashed_sorted_clusters):\n",
        "    def few_deviations(squashed_sorted_cluster):\n",
        "        _, value_info = squashed_sorted_cluster\n",
        "        _, most_common_count = value_info[0]\n",
        "        total_values = sum(number for _, number in value_info)\n",
        "        deviating_values = total_values - most_common_count\n",
        "        return deviating_values / total_values < RATIO\n",
        "\n",
        "    return list(filter(few_deviations, squashed_sorted_clusters))\n",
        "\n",
        "\n",
        "def filter_squashed_sorted_clusters(squashed_sorted_clusters):\n",
        "    try:\n",
        "        squashed_sorted_clusters = filter_radius(squashed_sorted_clusters, number_metric)\n",
        "    except TypeError:\n",
        "        squashed_sorted_clusters = filter_radius(squashed_sorted_clusters, string_metric)\n",
        "    return filter_ratio(squashed_sorted_clusters)\n",
        "\n",
        "\n",
        "def get_result_set(df, algo_type, algo_config):\n",
        "    algo = algo_type()\n",
        "    algo.load_data(table=df, **algo_config)\n",
        "    algo.execute(**algo_config)\n",
        "    return set(algo.get_fds())\n",
        "\n",
        "\n",
        "def make_display_df(squashed_sorted_clusters, original_df, lhs_indices, rhs_index):\n",
        "    display_rows = []\n",
        "    for lhs, value_info in squashed_sorted_clusters:\n",
        "        for value, count in value_info:\n",
        "            display_rows.append((count, *lhs, value))\n",
        "    return pandas.DataFrame(display_rows, columns=['rows count']\n",
        "                            + [original_df.columns[col] for col in lhs_indices]\n",
        "                            + [original_df.columns[rhs_index]])\n",
        "\n",
        "def print_display_df(display_df):\n",
        "    df_lines = display_df.to_string(index=False).splitlines()\n",
        "    print(df_lines[0])\n",
        "    print(Fore.GREEN + df_lines[1] + Style.RESET_ALL)\n",
        "    print(Fore.RED + '\\n'.join(islice(df_lines, 2, None)) + Style.RESET_ALL)\n",
        "    print()\n",
        "\n",
        "def get_typo_candidates_df(df, display_df):\n",
        "    def get_mask(attr_info):\n",
        "        col_name, value = attr_info\n",
        "        return df[col_name] == value\n",
        "\n",
        "    typo_candidate_rows = []\n",
        "    typo_candidate_row_indices = []\n",
        "\n",
        "    for index, row in display_df.iterrows():\n",
        "        mask = reduce(operator.and_, map(get_mask, islice(row.items(), 1, None)))\n",
        "        found_rows = df[mask]\n",
        "        typo_candidate_rows.append(found_rows.values[0])\n",
        "        typo_candidate_row_indices.append(found_rows.index.values[0])\n",
        "    return pandas.DataFrame(typo_candidate_rows, columns=df.columns, index=typo_candidate_row_indices)"
      ],
      "metadata": {
        "id": "GBa3kfddu4cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Printing dataset sample."
      ],
      "metadata": {
        "id": "ZfxlnUdf3FV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv(DATASET_PATH, sep=SEPARATOR, header=HEADER)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdMljz5E15pX",
        "outputId": "b48504b3-8f55-4f9b-af23-5e288d3e06d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       id      worker_name supervisor_surname       workshop  salary                   job_post\n",
            "0    404f50cb-caf0-4974-97f9-9463434537e1   Jennifer Moore        Galen Calla    Yogatacular     980    Client Solution Analyst\n",
            "1    b5e38281-9c09-49bf-91f5-c55397df4d43       Edward Lee      Carrie Silvia    MonsterWorq     905  Front-End Loader Operator\n",
            "2    972b299d-2f27-4d6d-81d2-8effbc543bf1        Brian Lee      Shena Desiree  Talkspiration     700             Farm Assistant\n",
            "3    3241fb48-5a15-4638-bd68-d915834a3f89   Kenneth Turner        Paul Jeffry     Verbalthon     980    Client Solution Analyst\n",
            "4    9cbb9026-f157-4a01-aace-a42b05ab2a28   Betty Campbell    Addyson Aaliyah     SpeakerAce     800            Physiotherapist\n",
            "..                                    ...              ...                ...            ...     ...                        ...\n",
            "940  9cd700bc-b3d9-439d-afe9-945c2a20bc37    Richard Lopez        Galen Calla    Yogatacular     845   Senior Financial Planner\n",
            "941  cc199ff4-453a-4ae5-9fbd-b45d72fa952a  Helen Rodriguez      Carrie Silvia    MonsterWorq     465                Electrician\n",
            "942  de650347-880a-42a2-88c9-4329f26fb912      Karen White      Carrie Silvia    MonsterWorq     510       JavaScript Developer\n",
            "943  ae604e24-e040-4d50-b685-5b4897ab9ae9    Charles Smith      Shena Desiree  Talkspiration     975              Store Manager\n",
            "944  d5cb954a-e942-47ae-9b62-b57f7a84c2db        Jeff King      Carrie Silvia    MonsterWorq     465                Electrician\n",
            "\n",
            "[945 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting typo discovery scenario with parameters:"
      ],
      "metadata": {
        "id": "5XtQJov86Lgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(CONFIG_STRING)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLvN6CRF6Pcf",
        "outputId": "f23d646c-b71b-4026-89c4-34dd0c904617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting typo discovery scenario with parameters:\n",
            "RADIUS=3\n",
            "RATIO=0.1\n",
            "ERROR=0.005\n",
            "DATASET_PATH='Workshop.csv'\n",
            "EXACT_ALGORITHM='HyFD'\n",
            "APPROXIMATE_ALGORITHM='Pyro'\n",
            "HEADER=0\n",
            "SEPARATOR=','\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Searching for almost holding FDs.\n"
      ],
      "metadata": {
        "id": "RJRKWg8S6Q9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Searching for almost holding FDs...')\n",
        "print()\n",
        "holding_fds = get_result_set(df, EXACT_ALGORITHM_TYPE, EXACT_ALGO_CONFIG)\n",
        "close_fds = get_result_set(df, APPROXIMATE_ALGORITHM_TYPE, APPROXIMATE_ALGO_CONFIG)\n",
        "almost_holding_fds = sorted(close_fds - holding_fds, key=lambda fd: fd.to_index_tuple())\n",
        "print('Found! Almost holding FDs:')\n",
        "print('\\n'.join(map(str, almost_holding_fds)))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SXtg3-h6K_0",
        "outputId": "07eb7265-57d0-4e2d-887d-6f11f4f5d2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for almost holding FDs...\n",
            "\n",
            "Found! Almost holding FDs:\n",
            "[supervisor_surname salary] -> job_post\n",
            "[supervisor_surname job_post] -> salary\n",
            "[workshop] -> supervisor_surname\n",
            "[workshop salary] -> job_post\n",
            "[workshop job_post] -> salary\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selecting FD with index 2."
      ],
      "metadata": {
        "id": "7qnyxPu866fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Selecting FD with index {FD_INDEX}:')\n",
        "lhs_indices, rhs_index = almost_holding_fds[FD_INDEX].to_index_tuple()\n",
        "squashed_sorted_clusters = filter_squashed_sorted_clusters(\n",
        "    get_squashed_sorted_clusters(df, lhs_indices, rhs_index))\n",
        "if not squashed_sorted_clusters:\n",
        "    print('Nothing found. Try another FD or relax restrictions (radius, ratio, error).')\n",
        "else:\n",
        "    display_df = make_display_df(squashed_sorted_clusters, df, lhs_indices, rhs_index)\n",
        "    print_display_df(display_df)\n",
        "    print('Typo candidates and context:')\n",
        "    print(get_typo_candidates_df(df, display_df).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMAzlZkI0rRY",
        "outputId": "670ef0f6-8e55-4d19-fe73-ca73d9bd3b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting FD with index 2:\n",
            " rows count    workshop supervisor_surname\n",
            "\u001b[32m        198 Yogatacular        Galen Calla\u001b[0m\n",
            "\u001b[31m          1 Yogatacular      Galen Calella\u001b[0m\n",
            "\n",
            "Typo candidates and context:\n",
            "                                     id       worker_name supervisor_surname     workshop  salary                 job_post\n",
            "0  404f50cb-caf0-4974-97f9-9463434537e1    Jennifer Moore        Galen Calla  Yogatacular     980  Client Solution Analyst\n",
            "7  ddba9118-ec89-472d-9f3f-bebd919f0e3a  William Robinson      Galen Calella  Yogatacular     975            Store Manager\n"
          ]
        }
      ]
    }
  ]
}